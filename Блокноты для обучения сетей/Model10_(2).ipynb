{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmt2cetgSwra"
      },
      "source": [
        "# Поехали\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdA2-qakSvF3",
        "outputId": "2a6c3551-9d23-4b0a-9205-3b4997f57683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.models import Model, load_model # Импортируем модели keras: Model\n",
        "from tensorflow.keras.layers import Input, Rescaling, Conv2DTranspose, Add, concatenate, Activation, SpatialDropout2D, MaxPooling2D, AveragePooling2D, Conv2D, BatchNormalization # Импортируем стандартные слои keras\n",
        "from tensorflow.keras import backend as K # Импортируем модуль backend keras'а\n",
        "from tensorflow.keras.optimizers import Adam, Nadam # Импортируем оптимизатор Adam\n",
        "from tensorflow.keras import utils # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\n",
        "from keras import regularizers\n",
        "from keras.callbacks import Callback\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import glob\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import gc\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "Colab = True\n",
        "try:\n",
        "    from google.colab import drive\n",
        "except:\n",
        "    Colab = False\n",
        "\n",
        "if Colab:\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Подключаем Google drive\n",
        "    drive.mount('/content/drive')\n",
        "    CrPath = \"/content/drive/MyDrive/Henetic/\"\n",
        "else:\n",
        "    Acer = not os.path.exists(\"E:/w/Diplom/\")\n",
        "    CrPath = \"C:/w/Hacatons/Vladik/\" if Acer else \"E:/w/Hacatons/Vladik/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "txloudRX1lPQ"
      },
      "outputs": [],
      "source": [
        "ImgSz =256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wp7qyOgfTVub"
      },
      "outputs": [],
      "source": [
        "def MakeAug(image, mask, a = 9, verbose = False, p = 1):\n",
        "    if a == 0:\n",
        "        aug = A.HorizontalFlip(p=p)\n",
        "    elif a == 1:\n",
        "        aug = A.VerticalFlip(p=p)\n",
        "    elif a == 2:\n",
        "        aug = A.RandomRotate90(p=p)\n",
        "    elif a == 3:\n",
        "        aug = A.RandomRotate90(p=p)\n",
        "    elif a == 4:\n",
        "        aug = A.Transpose(p=p)\n",
        "    elif a == 5:\n",
        "        aug = A.ElasticTransform(p=p, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
        "    elif a == 6:\n",
        "        aug = A.GridDistortion(p=p)\n",
        "    elif a == 7:\n",
        "        aug = A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)\n",
        "    elif a == 8:\n",
        "        original_height, original_width = image.shape[:2]\n",
        "        aug = A.RandomSizedCrop(min_max_height=(original_height*0.7, original_width*0.7), height=original_height, width=original_width, p=1)\n",
        "    elif a == 9:\n",
        "        original_height, original_width = image.shape[:2]\n",
        "        aug = A.Compose([\n",
        "            A.VerticalFlip(p=p/2),\n",
        "            A.HorizontalFlip(p=p / 2),\n",
        "            A.RandomRotate90(p=p/2),\n",
        "            A.CLAHE(p=0.8),\n",
        "            A.RandomGamma(p=0.8)])\n",
        "\n",
        "\n",
        "\n",
        "    augmented = aug(image=image, mask=mask)\n",
        "\n",
        "    image_h_flipped = augmented['image']\n",
        "    mask_h_flipped = augmented['mask']\n",
        "\n",
        "    return image_h_flipped, mask_h_flipped\n",
        "\n",
        "class EyeDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Класс датасета, организующий загрузку и получение изображений и соответствующих разметок\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_folder: str, transform=None, ImgReadMode=cv2.IMREAD_COLOR):\n",
        "        self.class_ids = {\"vessel\": 1}\n",
        "\n",
        "        self.data_folder = data_folder\n",
        "        self.transform = transform\n",
        "        self._image_files = glob.glob(f\"{CrPath}{data_folder}/f*.png\")\n",
        "        \n",
        "        EyeDataset.ImgReadMode = ImgReadMode  # знаю, что так использовать стат перем плохая идея\n",
        "\n",
        "        self.CrImgFile = ''\n",
        "\n",
        "    @staticmethod\n",
        "    def read_image(path: str) -> np.ndarray:\n",
        "        image = cv2.imread(str(path), EyeDataset.ImgReadMode)\n",
        "\n",
        "        if EyeDataset.ImgReadMode != cv2.IMREAD_GRAYSCALE:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = np.array(image, dtype=np.ubyte)\n",
        "\n",
        "        #if image.shape[0] * image.shape[0] != 256*256:\n",
        "        #    print('Ошибка размера Img') \n",
        "        #    print(path, image.shape)\n",
        "\n",
        "        return image\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_polygon(coordinates: dict, image_size: tuple) -> np.ndarray:\n",
        "        mask = np.zeros(image_size, dtype=np.ubyte)\n",
        "        if len(coordinates) == 1:\n",
        "            points = [np.int32(coordinates)]\n",
        "            cv2.fillPoly(mask, points, 1)\n",
        "        else:\n",
        "            for polygon in coordinates:\n",
        "                points = [np.int32([polygon])]\n",
        "                cv2.fillPoly(mask, points, 1)\n",
        "        return mask\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_mask(shape: dict, image_size: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Метод для парсинга фигур из geojson файла\n",
        "        \"\"\"\n",
        "        mask = np.zeros(image_size, dtype=np.ubyte)\n",
        "        coordinates = shape['coordinates']\n",
        "        if shape['type'] == 'MultiPolygon':\n",
        "            for polygon in coordinates:\n",
        "                mask += EyeDataset.parse_polygon(polygon, image_size)\n",
        "        else:\n",
        "            mask += EyeDataset.parse_polygon(coordinates, image_size)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def read_layout(self, path: str, image_size: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Метод для чтения geojson разметки и перевода в numpy маску\n",
        "        \"\"\"\n",
        "        with open(path, 'r', encoding='cp1251') as f:  # some files contain cyrillic letters, thus cp1251\n",
        "            json_contents = json.load(f)\n",
        "\n",
        "        num_channels = 1 + max(self.class_ids.values())\n",
        "        mask_channels = [np.zeros(image_size, dtype=np.ubyte) for _ in range(num_channels)]\n",
        "        mask = np.zeros(image_size, dtype=np.ubyte)\n",
        "\n",
        "        if type(json_contents) == dict and json_contents['type'] == 'FeatureCollection':\n",
        "            features = json_contents['features']\n",
        "        elif type(json_contents) == list:\n",
        "            features = json_contents\n",
        "        else:\n",
        "            features = [json_contents]\n",
        "\n",
        "        for shape in features:\n",
        "            channel_id = self.class_ids[\"vessel\"]\n",
        "            mask = self.parse_mask(shape['geometry'], image_size)\n",
        "            mask_channels[channel_id] = np.maximum(mask_channels[channel_id], mask)\n",
        "\n",
        "        mask_channels[0] = 1 - np.max(mask_channels[1:], axis=0)\n",
        "\n",
        "        return np.stack(mask_channels, axis=-1)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        # Достаём имя файла по индексу\n",
        "        image_path = self._image_files[idx]\n",
        "\n",
        "        self.CrImgFile = image_path\n",
        "\n",
        "        # Получаем соответствующий файл разметки\n",
        "        m_path = image_path.replace(r\"/f\", r\"/m\")\n",
        "\n",
        "        image = self.read_image(image_path)\n",
        "        \n",
        "        mask = cv2.imread(str(m_path), cv2.IMREAD_GRAYSCALE)\n",
        "        #print(m_path)\n",
        "        #self.read_layout(json_path, image.shape[:2])\n",
        "        #if mask.shape[0] * mask.shape[0] != 256*256:\n",
        "        #    print('Ошибка размера mask') \n",
        "        #    print(m_path, mask.shape) \n",
        "        sample = {'image': image,\n",
        "                  'mask': mask/255}\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(**sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._image_files)\n",
        "\n",
        "    # Метод для проверки состояния датасета\n",
        "    def make_report(self):\n",
        "        reports = []\n",
        "        if (not self.data_folder):\n",
        "            reports.append(\"Путь к датасету не указан\")\n",
        "        if (len(self._image_files) == 0):\n",
        "            reports.append(\"Изображения для распознавания не найдены\")\n",
        "        else:\n",
        "            reports.append(f\"Найдено {len(self._image_files)} изображений\")\n",
        "        cnt_images_without_masks = sum(\n",
        "            [1 - len(glob.glob(filepath.replace(\"png\", \"geojson\"))) for filepath in self._image_files])\n",
        "        if cnt_images_without_masks > 0:\n",
        "            reports.append(f\"Найдено {cnt_images_without_masks} изображений без разметки\")\n",
        "        else:\n",
        "            reports.append(f\"Для всех изображений есть файл разметки\")\n",
        "        return reports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e7jLfwktH1jn"
      },
      "outputs": [],
      "source": [
        "def unetWithMask(num_classes=2, input_shape=(256, 256, 1)):\n",
        "    img_input = Input(input_shape)  # Создаем входной слой с размерностью input_shape\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input)  # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)  # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    block_1_out = Activation('relu')(x)  # Добавляем слой Activation и запоминаем в переменной block_1_out\n",
        "\n",
        "    block_1_out_mask = Conv2D(64, (1, 1), padding='same')(\n",
        "        block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\n",
        "\n",
        "    block_1_2_out_mask = Conv2D(128, (1, 1), padding='same', strides = (2,2))(\n",
        "        block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\n",
        "\n",
        "    block_1_3_out_mask = Conv2D(256, (1, 1), padding='same', strides = (4,4))(\n",
        "        block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\n",
        "\n",
        "    block_1_4_out_mask = Conv2D(512, (1, 1), padding='same', strides = (8,8))(\n",
        "        block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_1_out)  # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)  # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)  # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = SpatialDropout2D(0.3)(x)\n",
        "    #x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    block_2_out = Activation('relu')(x)  # Добавляем слой Activation и запоминаем в переменной block_2_out\n",
        "\n",
        "    block_2_out_mask = Conv2D(128, (1, 1), padding='same')(\n",
        "        block_2_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_2_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_2_out)  # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    block_3_out = Activation('relu')(x)  # Добавляем слой Activation и запоминаем в переменной block_3_out\n",
        "\n",
        "    block_3_out_mask = Conv2D(256, (1, 1), padding='same')(\n",
        "        block_3_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_3_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_3_out)  # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)  # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    block_4_out = Activation('relu')(x)  # Добавляем слой Activation и запоминаем в переменной block_4_out\n",
        "\n",
        "    block_4_out_mask = Conv2D(512, (1, 1), padding='same')(\n",
        "        block_4_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_4_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_4_out)  # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)  # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)  # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)  # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    # UP 1\n",
        "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(\n",
        "        x)  # Добавляем слой Conv2DTranspose с 512 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Add()([x, block_4_out, block_1_4_out_mask,\n",
        "                     block_4_out_mask])  # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 512 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 512 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    # UP 2\n",
        "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(\n",
        "        x)  # Добавляем слой Conv2DTranspose с 256 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Add()([x, block_3_out, block_1_3_out_mask,\n",
        "                     block_3_out_mask])  # Объединем текущий слой со слоем block_3_out и слоем-маской block_3_out_mask\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 256 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 256 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    # UP 3\n",
        "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(\n",
        "        x)  # Добавляем слой Conv2DTranspose с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Add()([x, block_2_out, block_1_2_out_mask,\n",
        "                     block_2_out_mask])  # Объединем текущий слой со слоем block_2_out и слоем-маской block_2_out_mask\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    # UP 4\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)  # Добавляем слой Conv2DTranspose с 64 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Add()([x, block_1_out,  block_1_out_mask])  # Объединем текущий слой со слоем block_1_out и слоем-маской block_1_out_mask\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(\n",
        "        x)  # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n",
        "    \n",
        "    model = Model(img_input, x)  # Создаем модель с входом 'img_input' и выходом 'x'\n",
        "    \n",
        "    model.compile(optimizer=Nadam(learning_rate=0.005),\n",
        "                  loss='categorical_crossentropy')\n",
        "\n",
        "\n",
        "    return model  # Возвращаем сформированную модель\n",
        "\n",
        "\n",
        "def dice_coef_np(y_true, y_pred):\n",
        "    return (2. * np.sum(y_true * y_pred) + 1.) / (np.sum(y_true) + np.sum(y_pred) + 1.)\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "InBatch = 0\n",
        "Au = 0\n",
        "\n",
        "def Generate(dataset, BatchSz = 16, AuSteps = 89*4, Test = False, ImgSz = ImgSz):\n",
        "    InBatch = BatchSz\n",
        "    \n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    while(True):\n",
        "        random.seed(11)\n",
        "        for Au in range(AuSteps):\n",
        "            for sample in dataset:\n",
        "\n",
        "                # if Step < FileIndex*50: # аккуратненько чтоб не вникать в тонкости устройства dataset пропускаем уже сделанные позиции (использую при обрыве выполнения)\n",
        "                #    Step+= 1\n",
        "                # continue\n",
        "\n",
        "                m = sample[\"mask\"][:, :]\n",
        "                Img = sample['image']\n",
        "\n",
        "                Sz = Img.shape[:2]\n",
        "\n",
        "                #Img = cv2.resize(Img, (ImgSz, ImgSz))\n",
        "                Mask = m #cv2.resize(m, (ImgSz, ImgSz))\n",
        "\n",
        "                if Au > 0 or Test:\n",
        "                    Img, Mask = MakeAug(Img, Mask, verbose= False)\n",
        "\n",
        "                if InBatch > 0:\n",
        "                    Mask = Mask.reshape((1, ImgSz, ImgSz, 1))\n",
        "                    Mask1 = 1 - Mask\n",
        "\n",
        "                    Mask = np.concatenate([Mask, Mask1], 3)\n",
        "                    X.append(Img.reshape((1, ImgSz, ImgSz, 1)))\n",
        "                    Y.append(Mask)\n",
        "                    \n",
        "                    InBatch -= 1\n",
        "                else:\n",
        "                    yield (np.concatenate(X), np.concatenate(Y))\n",
        "                    X = []\n",
        "                    Y = []\n",
        "                    InBatch = BatchSz\n",
        "\n",
        "                Img = None\n",
        "                Mask = None\n",
        "\n",
        "                gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsOyAL5CUVKb",
        "outputId": "528b273e-b5ed-4918-ed34-6bdaa9a46c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Не удалось загрузить веса\n",
            "Читаем тестовый набор\n",
            "Поехали\n",
            "356/356 [==============================] - 1148s 3s/step - loss: 0.0836\n",
            "16/16 [==============================] - 13s 486ms/step\n",
            "Сохранена лучшая модель.  0 0.04125835319351292 0.04125835319351292\n",
            "356/356 [==============================] - 1150s 3s/step - loss: 0.0665\n",
            "16/16 [==============================] - 8s 514ms/step\n",
            "1 0.020530356810879478 0.04125835319351292\n",
            "356/356 [==============================] - 1144s 3s/step - loss: 0.0628\n",
            "16/16 [==============================] - 8s 514ms/step\n",
            "Сохранена лучшая модель.  2 0.06477536844314412 0.06477536844314412\n",
            "356/356 [==============================] - 1157s 3s/step - loss: 0.0586\n",
            "16/16 [==============================] - 8s 515ms/step\n",
            "3 0.02512766124843374 0.06477536844314412\n",
            "356/356 [==============================] - 1232s 3s/step - loss: 0.0580\n",
            "16/16 [==============================] - 8s 509ms/step\n",
            "Сохранена лучшая модель.  4 0.08315812477182714 0.08315812477182714\n",
            " 98/356 [=======>......................] - ETA: 14:43 - loss: 0.0525"
          ]
        }
      ],
      "source": [
        "'''\n",
        "try:\n",
        "    model = load_model(rf'{CrPath}model10.h5')\n",
        "    model.load_weights(rf'{CrPath}cr.npy')\n",
        "    print('Прочитаны веса')\n",
        "\n",
        "except:\n",
        "    try:\n",
        "        print(rf'{CrPath}model10.h5')\n",
        "        model = load_model(rf'{CrPath}model10.h5')\n",
        "        print('Прочитана модель')\n",
        "    except:\n",
        "        model = unetWithMask()\n",
        "        print('Модель создана со случайными весами')\n",
        "'''\n",
        "model = unetWithMask()\n",
        "\n",
        "try:\n",
        "    model.load_weights(rf'{CrPath}W10.h5')\n",
        "    print('Прочитаны веса')\n",
        "except:\n",
        "    print('Не удалось загрузить веса')\n",
        "\n",
        "#model = load_model(rf'{CrPath}W10.h5')\n",
        "\n",
        "Best = 0\n",
        "Index = 0\n",
        "dataset = EyeDataset(\"trainfull\", ImgReadMode=cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "G = Generate(dataset)\n",
        "\n",
        "\n",
        "'''\n",
        "Test = Generate(dataset, Test = True)\n",
        "print('Поехали')\n",
        "\n",
        "#TestX = [0]*64\n",
        "#TestY = [0]*64\n",
        "\n",
        "#X, Y = next(G)\n",
        "\n",
        "print('Генерируем Test набор')\n",
        "index = 0\n",
        "\n",
        "TestX = [None]*128\n",
        "TestY = [None]*128 \n",
        "\n",
        "try:\n",
        "    TestX = np.load('TestX.npy')\n",
        "    TestY = np.load('TestY.npy')\n",
        "except:\n",
        "    for index in tqdm(range(128)):\n",
        "        X, Y = next(Test)\n",
        "\n",
        "        TestX[index] = X\n",
        "        TestY[index] = Y\n",
        "\n",
        "    try:\n",
        "        TestX = np.concatenate(TestX)\n",
        "        TestY = np.concatenate(TestY)\n",
        "    except:\n",
        "        print('')\n",
        "\n",
        "    np.save(fr'{CrPath}TestX1.npy', TestX)\n",
        "    np.save(fr'{CrPath}TestY1.npy', TestY)\n",
        "'''\n",
        "print('Читаем тестовый набор')\n",
        "TestX = np.load(fr'{CrPath}TestX1.npy')\n",
        "TestY = np.load(fr'{CrPath}TestY1.npy')\n",
        "print('Поехали')\n",
        "\n",
        "while True:\n",
        "    #X, Y = next(G)\n",
        "    history = model.fit(G, epochs=1, steps_per_epoch=89*4, batch_size=16, verbose=1, use_multiprocessing=True)\n",
        "    \n",
        "    model.save(rf'{CrPath}model10.h5')\n",
        "    model.save_weights(rf'{CrPath}W10.h5')\n",
        "    gc.collect()\n",
        "\n",
        "    Res = model.predict(TestX[:512], verbose=True)[:, :, :, 0:1]\n",
        "    er = dice_coef_np(Res, TestY[:512])   \n",
        "\n",
        "    if er > Best:\n",
        "        Best = er\n",
        "        model.save(rf'{CrPath}Best10.h5')\n",
        "        model.save_weights(rf'{CrPath}BestW10.h5')\n",
        "        print('Сохранена лучшая модель. ', Index, er, Best)\n",
        "    else:\n",
        "        print(Index, er, Best)\n",
        "\n",
        "    Index += 1\n",
        "    #np.save(rf'{CrPath}Res.npy', Res)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}