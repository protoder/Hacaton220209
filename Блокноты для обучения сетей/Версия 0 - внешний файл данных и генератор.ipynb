{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Все\n"
      ],
      "metadata": {
        "id": "qlMt6so2prGb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVe6LgIIVkuO",
        "outputId": "af4d9ea3-595e-465f-90a4-8055d37a2e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.models import load_model, Model  # Импортируем модели keras: Model\n",
        "from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, SpatialDropout2D, MaxPooling2D, \\\n",
        "    AveragePooling2D, Conv2D, BatchNormalization  # Импортируем стандартные слои keras\n",
        "from tensorflow.keras import backend as K  # Импортируем модуль backend keras'а\n",
        "from tensorflow.keras.optimizers import Adam  # Импортируем оптимизатор Adam\n",
        "from tensorflow.keras import \\\n",
        "    utils  # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\n",
        "from keras import regularizers\n",
        "from keras.callbacks import Callback\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "GrayScaled = True\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# random.seed(1)\n",
        "\n",
        "Colab = True\n",
        "try:\n",
        "    from google.colab import drive\n",
        "except:\n",
        "    Colab = False\n",
        "\n",
        "if Colab:\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Подключаем Google drive\n",
        "    drive.mount('/content/drive')\n",
        "    CrPath = \"/content/drive/MyDrive/Henetic/\"\n",
        "else:\n",
        "    Acer = not os.path.exists(\"E:/w/Diplom/\")\n",
        "    CrPath = \"C:/w/Hacatons/Vladik/\" if Acer else \"E:/w/Hacatons/Vladik/\"\n",
        "\n",
        "# типовая Unet 5 слоев\n",
        "def unetWithMask(num_classes=2, input_shape=(128, 128, 1)):\n",
        "    img_input = Input(input_shape)  # Создаем входной слой с размерностью input_shape\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input)  # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)  # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    block_1_out = Activation('relu')(x)  # Добавляем слой Activation и запоминаем в переменной block_1_out\n",
        "\n",
        "    block_1_out_mask = Conv2D(64, (1, 1), padding='same')(\n",
        "        block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_1_out)  # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)  # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)  # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    block_2_out = Activation('relu')(x)  # Добавляем слой Activation и запоминаем в переменной block_2_out\n",
        "\n",
        "    block_2_out_mask = Conv2D(128, (1, 1), padding='same')(\n",
        "        block_2_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_2_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_2_out)  # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    block_3_out = Activation('relu')(x)  # Добавляем слой Activation и запоминаем в переменной block_3_out\n",
        "\n",
        "    block_3_out_mask = Conv2D(256, (1, 1), padding='same')(\n",
        "        block_3_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_3_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_3_out)  # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)  # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)  # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    block_4_out = Activation('relu')(x)  # Добавляем слой Activation и запоминаем в переменной block_4_out\n",
        "\n",
        "    block_4_out_mask = Conv2D(512, (1, 1), padding='same')(\n",
        "        block_4_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_4_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_4_out)  # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)  # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)  # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)  # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    # UP 1\n",
        "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(\n",
        "        x)  # Добавляем слой Conv2DTranspose с 512 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_4_out,\n",
        "                     block_4_out_mask])  # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 512 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 512 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    # UP 2\n",
        "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(\n",
        "        x)  # Добавляем слой Conv2DTranspose с 256 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_3_out,\n",
        "                     block_3_out_mask])  # Объединем текущий слой со слоем block_3_out и слоем-маской block_3_out_mask\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 256 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 256 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    # UP 3\n",
        "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(\n",
        "        x)  # Добавляем слой Conv2DTranspose с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_2_out,\n",
        "                     block_2_out_mask])  # Объединем текущий слой со слоем block_2_out и слоем-маской block_2_out_mask\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    # UP 4\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)  # Добавляем слой Conv2DTranspose с 64 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_1_out,\n",
        "                     block_1_out_mask])  # Объединем текущий слой со слоем block_1_out и слоем-маской block_1_out_mask\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)  # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)  # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)  # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(\n",
        "        x)  # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n",
        "\n",
        "    model = Model(img_input, x)  # Создаем модель с входом 'img_input' и выходом 'x'\n",
        "\n",
        "    # Компилируем модель\n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss='categorical_crossentropy')\n",
        "\n",
        "    return model  # Возвращаем сформированную модель\n",
        "\n",
        "# метрика\n",
        "def dice_coef_np(y_true, y_pred):\n",
        "    return (2. * np.sum(y_true * y_pred) + 1.) / (np.sum(y_true) + np.sum(y_pred) + 1.)\n",
        "\n",
        "# Генератор данных. Нарезает npy файл данных\n",
        "def GetBatch(Data):\n",
        "    while(True):\n",
        "        StartBatch =  0\n",
        "\n",
        "        while StartBatch < len(Data):\n",
        "            EndBatch = StartBatch + 16\n",
        "\n",
        "            InputX = Data[StartBatch:EndBatch, 0]\n",
        "            XShape = list(InputX.shape)\n",
        "            XShape.append(1)\n",
        "            InputX = InputX.reshape(XShape)\n",
        "\n",
        "            InputY = Data[StartBatch:EndBatch, 1]\n",
        "            StartBatch= EndBatch\n",
        "\n",
        "            YShape = list(InputY.shape)\n",
        "            YShape.append(1)\n",
        "            InputY = InputY.reshape(YShape)\n",
        "            InputY1 = 1 - InputY # исходно Y массив содержит лишь одby выход. Создаем комплементарный для удобства кроссэнропии\n",
        "\n",
        "            InputY = np.concatenate([InputY, InputY1], 3)\n",
        "\n",
        "            yield InputX/255, InputY\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка данных. Они лежат в файле numpy/train2.npy, формат [N, 2, 128, 128]\n",
        "Data = np.load(rf'{CrPath}numpy/train2.npy')\n",
        "\n",
        "print(Data.shape)\n",
        "\n",
        "# Выделяем тестовый набор\n",
        "Test = Data[-16*64:]\n",
        "Data = Data[:-16*64]\n",
        "\n",
        "TestX = Test[:, 0]\n",
        "XShape = list(TestX.shape)\n",
        "XShape.append(1)\n",
        "TestX = TestX.reshape(XShape)/255  # нормируем\n",
        "\n",
        "# для Y создаем комплементарный канал - так удобнее для кросс энтропии\n",
        "TestY = Test[:, 1]\n",
        "Test = None\n",
        "YShape = list(TestY.shape)\n",
        "YShape.append(1)\n",
        "TestY = TestY.reshape(YShape)\n",
        "TestY1 = 1 - TestY\n",
        "\n",
        "TestY = np.concatenate([TestY, TestY1], 3)\n",
        "TestY1 = None\n",
        "\n",
        "# Модель приспособлена для продолжения обучения после сбоев\n",
        "try:\n",
        "    model = unetWithMask()\n",
        "    model.load_weights(rf'{CrPath}cr.npy')\n",
        "    print('Прочитаны веса')\n",
        "  \n",
        "except:\n",
        "    model = load_model(rf'{CrPath}best.h5')\n",
        "    print('Прочитана модель')  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz0IgD3RWRGl",
        "outputId": "feb12288-561c-44ff-9902-813b1cb23ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(124416, 2, 128, 128)\n",
            "Прочитана модель\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Best = 0\n",
        "Index = 0\n",
        "G = GetBatch(Data)\n",
        "\n",
        "print('Поехали')\n",
        "\n",
        "\n",
        "while True:\n",
        "    history = model.fit(G, epochs=1, steps_per_epoch=7776, verbose = 1, use_multiprocessing=True)\n",
        "    # Для большего контроля predict вынесен из fit\n",
        "    Res = model.predict(TestX, steps = 64, verbose=True)[:, :, :, 0:1]\n",
        "    er = dice_coef_np(Res, TestY)\n",
        "\n",
        "    Res = None\n",
        "\n",
        "    # запоминаем состояие на случай сбоя\n",
        "    if er > Best:\n",
        "        Best = er\n",
        "        model.save(rf'{CrPath}best.h5') # этот файл - результат работы сети\n",
        "        print('Сохранена лучшая модель. ', Index, er, Best)\n",
        "    else:\n",
        "        print(Index, er, Best)\n",
        "    \n",
        "    model.save(rf'{CrPath}cr.npy')\n",
        "    Index+= 1\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tR5Dy9QWiZO",
        "outputId": "2d5ddf98-45d8-4531-c836-f93f95640f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Поехали\n",
            "1410/7776 [====>.........................] - ETA: 28:53 - loss: 0.0602"
          ]
        }
      ]
    }
  ]
}